import * as vscode from 'vscode';
import axios from 'axios';
import { APIConfigService, APIConfig } from './APIConfigService';

export interface LLMRequest {
	prompt: string;
	problemContext: string;
	language: string;
}

export interface LLMResponse {
	generatedCode: string;
	explanation: string;
	success: boolean;
	error?: string;
}

export class LLMService {
	private apiConfigService: APIConfigService;
	private mockMode: boolean = false;

	constructor(apiConfigService: APIConfigService) {
		this.apiConfigService = apiConfigService;

		// æ£€æŸ¥æ˜¯å¦æœ‰APIå¯†é’¥é…ç½®
		if (!this.apiConfigService.hasValidConfig()) {
			console.log('âš ï¸ æœªé…ç½®APIå¯†é’¥ï¼Œå¯ç”¨æ¨¡æ‹Ÿæ¨¡å¼');
			this.mockMode = true;

			// æ˜¾ç¤ºé…ç½®æç¤º
			vscode.window.showWarningMessage(
				'ğŸ”‘ Prompt Pilot: æœªæ£€æµ‹åˆ°æœ‰æ•ˆçš„APIé…ç½®ï¼Œå½“å‰ä¸ºæ¨¡æ‹Ÿæ¨¡å¼ã€‚',
				'ç«‹å³é…ç½®', 'æŸ¥çœ‹æŒ‡å—', 'ç¨åé…ç½®'
			).then(selection => {
				if (selection === 'ç«‹å³é…ç½®') {
					vscode.commands.executeCommand('prompt-pilot.configureAPI');
				} else if (selection === 'æŸ¥çœ‹æŒ‡å—') {
					vscode.commands.executeCommand('workbench.action.openSettings', 'prompt-pilot');
				}
			});
		} else {
			console.log('âœ… APIé…ç½®æœ‰æ•ˆï¼Œä½¿ç”¨çœŸå®æ¨¡å¼');
			this.mockMode = false;
		}
	}

	/**
	 * æ£€æŸ¥æ˜¯å¦ä¸ºæ¨¡æ‹Ÿæ¨¡å¼
	 */
	public isMockMode(): boolean {
		return this.mockMode;
	}

	/**
	 * åˆ·æ–°é…ç½®çŠ¶æ€
	 */
	public refreshConfig(): void {
		const wasInMockMode = this.mockMode;
		this.mockMode = !this.apiConfigService.hasValidConfig();

		if (wasInMockMode && !this.mockMode) {
			console.log('âœ… æ£€æµ‹åˆ°æœ‰æ•ˆAPIé…ç½®ï¼Œåˆ‡æ¢åˆ°çœŸå®æ¨¡å¼');
			vscode.window.showInformationMessage('ğŸ‰ APIé…ç½®ç”Ÿæ•ˆï¼Œç°åœ¨å¯ä»¥ä½¿ç”¨çœŸå®AIæœåŠ¡äº†ï¼');
		} else if (!wasInMockMode && this.mockMode) {
			console.log('âš ï¸ APIé…ç½®å¤±æ•ˆï¼Œåˆ‡æ¢åˆ°æ¨¡æ‹Ÿæ¨¡å¼');
			vscode.window.showWarningMessage('âš ï¸ APIé…ç½®æ— æ•ˆï¼Œå·²åˆ‡æ¢åˆ°æ¨¡æ‹Ÿæ¨¡å¼');
		}
	}

	async generateCode(request: LLMRequest): Promise<LLMResponse> {
		// å¦‚æœæ˜¯æ¨¡æ‹Ÿæ¨¡å¼ï¼Œè¿”å›ç¤ºä¾‹ä»£ç 
		if (this.mockMode) {
			return this.getMockCodeResponse(request);
		}

		const config = this.apiConfigService.getConfig();

		try {
			const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¼–ç¨‹åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„promptå’Œé—®é¢˜æè¿°ç”Ÿæˆé«˜è´¨é‡çš„ä»£ç ã€‚

è¦æ±‚ï¼š
1. ä»£ç åº”è¯¥æ˜¯å®Œæ•´ä¸”å¯è¿è¡Œçš„
2. ä½¿ç”¨æœ€ä½³å®è·µå’Œé«˜æ•ˆç®—æ³•
3. åŒ…å«é€‚å½“çš„æ³¨é‡Š
4. è€ƒè™‘è¾¹ç•Œæƒ…å†µå’Œé”™è¯¯å¤„ç†

é—®é¢˜ä¸Šä¸‹æ–‡ï¼š${request.problemContext}
ç¼–ç¨‹è¯­è¨€ï¼š${request.language}`;

			if (config.provider === 'openai') {
				return await this.generateCodeWithOpenAI(request, systemPrompt, config);
			} else if (config.provider === 'azure') {
				return await this.generateCodeWithAzure(request, systemPrompt, config);
			} else if (config.provider === 'alibaba') {
				return await this.generateCodeWithAlibaba(request, systemPrompt, config);
			} else if (config.provider === 'moonshot') {
				return await this.generateCodeWithMoonshot(request, systemPrompt, config);
			} else if (config.provider === 'zhipu') {
				return await this.generateCodeWithZhipu(request, systemPrompt, config);
			} else if (config.provider === 'baichuan') {
				return await this.generateCodeWithBaichuan(request, systemPrompt, config);
			} else if (config.provider === 'custom') {
				return await this.generateCodeWithCustom(request, systemPrompt, config);
			} else {
				return {
					generatedCode: '',
					explanation: '',
					success: false,
					error: 'ä¸æ”¯æŒçš„APIæä¾›å•†'
				};
			}

		} catch (error: any) {
			return {
				generatedCode: '',
				explanation: '',
				success: false,
				error: `ç”Ÿæˆä»£ç å¤±è´¥: ${error.message}`
			};
		}
	}

	private async generateCodeWithOpenAI(request: LLMRequest, systemPrompt: string, config: APIConfig): Promise<LLMResponse> {
		const url = `${config.openai.baseUrl}/v1/chat/completions`;

		const response = await axios.post(
			url,
			{
				model: config.openai.model,
				messages: [
					{
						role: 'system',
						content: systemPrompt
					},
					{
						role: 'user',
						content: request.prompt
					}
				],
				temperature: config.openai.temperature,
				max_tokens: config.openai.maxTokens
			},
			{
				headers: {
					'Authorization': `Bearer ${config.openai.apiKey}`,
					'Content-Type': 'application/json'
				},
				timeout: config.timeout
			}
		);

		return this.processLLMResponse(response.data);
	}

	private async generateCodeWithAzure(request: LLMRequest, systemPrompt: string, config: APIConfig): Promise<LLMResponse> {
		const url = `${config.azure.endpoint}/openai/deployments/${config.azure.deploymentName}/chat/completions?api-version=${config.azure.apiVersion}`;

		const response = await axios.post(
			url,
			{
				messages: [
					{
						role: 'system',
						content: systemPrompt
					},
					{
						role: 'user',
						content: request.prompt
					}
				],
				temperature: config.openai.temperature,
				max_tokens: config.openai.maxTokens
			},
			{
				headers: {
					'api-key': config.azure.apiKey,
					'Content-Type': 'application/json'
				},
				timeout: config.timeout
			}
		);

		return this.processLLMResponse(response.data);
	}

	/**
	 * é˜¿é‡Œäº‘é€šä¹‰åƒé—®ä»£ç ç”Ÿæˆ
	 */
	private async generateCodeWithAlibaba(request: LLMRequest, systemPrompt: string, config: APIConfig): Promise<LLMResponse> {
		const { apiKey, baseUrl, model } = config.alibaba;

		// åˆ¤æ–­æ˜¯å¦ä½¿ç”¨å…¼å®¹æ¨¡å¼
		const isCompatibleMode = baseUrl.includes('compatible-mode');
		const url = isCompatibleMode
			? `${baseUrl}/chat/completions`
			: `${baseUrl}/api/v1/services/aigc/text-generation/generation`;

		let requestData: any;
		if (isCompatibleMode) {
			// OpenAIå…¼å®¹æ¨¡å¼
			requestData = {
				model: model,
				messages: [
					{
						role: 'system',
						content: systemPrompt
					},
					{
						role: 'user',
						content: request.prompt
					}
				],
				temperature: 0.7,
				max_tokens: 2048
			};
		} else {
			// é˜¿é‡Œäº‘åŸç”Ÿæ¨¡å¼
			requestData = {
				model: model,
				input: {
					messages: [
						{
							role: 'system',
							content: systemPrompt
						},
						{
							role: 'user',
							content: request.prompt
						}
					]
				},
				parameters: {
					temperature: 0.7,
					max_tokens: 2048
				}
			};
		}

		const response = await axios.post(
			url,
			requestData,
			{
				headers: {
					'Authorization': `Bearer ${apiKey}`,
					'Content-Type': 'application/json'
				},
				timeout: config.timeout
			}
		);

		if (isCompatibleMode) {
			return this.processLLMResponse(response.data);
		} else {
			// å¤„ç†é˜¿é‡Œäº‘åŸç”Ÿæ ¼å¼å“åº”
			const generatedText = response.data.output.text;
			const codeMatch = generatedText.match(/```(?:typescript|javascript|ts|js)?\n?([\s\S]*?)\n?```/);
			const generatedCode = codeMatch ? codeMatch[1].trim() : generatedText.trim();
			const explanation = generatedText.replace(/```(?:typescript|javascript|ts|js)?\n?[\s\S]*?\n?```/, '').trim();

			return {
				generatedCode,
				explanation,
				success: true
			};
		}
	}

	/**
	 * æœˆä¹‹æš—é¢ Kimi ä»£ç ç”Ÿæˆ
	 */
	private async generateCodeWithMoonshot(request: LLMRequest, systemPrompt: string, config: APIConfig): Promise<LLMResponse> {
		const url = `${config.moonshot.baseUrl}/v1/chat/completions`;

		const response = await axios.post(
			url,
			{
				model: config.moonshot.model,
				messages: [
					{
						role: 'system',
						content: systemPrompt
					},
					{
						role: 'user',
						content: request.prompt
					}
				],
				temperature: 0.7,
				max_tokens: 2048
			},
			{
				headers: {
					'Authorization': `Bearer ${config.moonshot.apiKey}`,
					'Content-Type': 'application/json'
				},
				timeout: config.timeout
			}
		);

		return this.processLLMResponse(response.data);
	}

	/**
	 * æ™ºè°± GLM ä»£ç ç”Ÿæˆ
	 */
	private async generateCodeWithZhipu(request: LLMRequest, systemPrompt: string, config: APIConfig): Promise<LLMResponse> {
		const url = `${config.zhipu.baseUrl}/api/paas/v4/chat/completions`;

		const response = await axios.post(
			url,
			{
				model: config.zhipu.model,
				messages: [
					{
						role: 'system',
						content: systemPrompt
					},
					{
						role: 'user',
						content: request.prompt
					}
				],
				temperature: 0.7,
				max_tokens: 2048
			},
			{
				headers: {
					'Authorization': `Bearer ${config.zhipu.apiKey}`,
					'Content-Type': 'application/json'
				},
				timeout: config.timeout
			}
		);

		return this.processLLMResponse(response.data);
	}

	/**
	 * ç™¾å·æ™ºèƒ½ä»£ç ç”Ÿæˆ
	 */
	private async generateCodeWithBaichuan(request: LLMRequest, systemPrompt: string, config: APIConfig): Promise<LLMResponse> {
		const url = `${config.baichuan.baseUrl}/v1/chat/completions`;

		const response = await axios.post(
			url,
			{
				model: config.baichuan.model,
				messages: [
					{
						role: 'system',
						content: systemPrompt
					},
					{
						role: 'user',
						content: request.prompt
					}
				],
				temperature: 0.7,
				max_tokens: 2048
			},
			{
				headers: {
					'Authorization': `Bearer ${config.baichuan.apiKey}`,
					'Content-Type': 'application/json'
				},
				timeout: config.timeout
			}
		);

		return this.processLLMResponse(response.data);
	}

	/**
	 * è‡ªå®šä¹‰APIä»£ç ç”Ÿæˆ
	 */
	private async generateCodeWithCustom(request: LLMRequest, systemPrompt: string, config: APIConfig): Promise<LLMResponse> {
		// é»˜è®¤ä½¿ç”¨OpenAIæ ¼å¼ï¼Œå¯æ ¹æ®éœ€è¦è°ƒæ•´
		const url = `${config.custom.baseUrl}/v1/chat/completions`;

		const response = await axios.post(
			url,
			{
				model: config.custom.model,
				messages: [
					{
						role: 'system',
						content: systemPrompt
					},
					{
						role: 'user',
						content: request.prompt
					}
				],
				temperature: 0.7,
				max_tokens: 2048
			},
			{
				headers: {
					'Authorization': `Bearer ${config.custom.apiKey}`,
					'Content-Type': 'application/json'
				},
				timeout: config.timeout
			}
		);

		return this.processLLMResponse(response.data);
	}

	private processLLMResponse(data: any): LLMResponse {
		const generatedText = data.choices[0].message.content;

		// æå–ä»£ç å—
		const codeMatch = generatedText.match(/```(?:typescript|javascript|ts|js)?\n?([\s\S]*?)\n?```/);
		const generatedCode = codeMatch ? codeMatch[1].trim() : generatedText.trim();

		// æå–è¯´æ˜
		const explanation = generatedText.replace(/```(?:typescript|javascript|ts|js)?\n?[\s\S]*?\n?```/, '').trim();

		return {
			generatedCode,
			explanation,
			success: true
		};
	}

	/**
	 * ç”ŸæˆPromptï¼ˆä¸“é—¨æ–¹æ³•ï¼Œä¸æå–ä»£ç å—ï¼‰
	 */
	async generatePrompt(taskDescription: string): Promise<{
		generatedPrompt: string;
		explanation: string;
		success: boolean;
		error?: string;
	}> {
		if (this.mockMode) {
			return this.getMockPromptResponse(taskDescription);
		}

		const config = this.apiConfigService.getConfig();

		try {
			const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Promptå·¥ç¨‹å¸ˆï¼Œæ“…é•¿å°†ç”¨æˆ·çš„ä»»åŠ¡æè¿°è½¬åŒ–ä¸ºé«˜è´¨é‡çš„AI Promptã€‚

è¯·æ ¹æ®ç”¨æˆ·çš„ä»»åŠ¡æè¿°ï¼Œç”Ÿæˆä¸€ä¸ªç»“æ„åŒ–ã€æ¸…æ™°ã€å…·ä½“çš„Promptã€‚

å¥½çš„Promptåº”è¯¥åŒ…å«ï¼š
1. æ˜ç¡®çš„ä»»åŠ¡æè¿°
2. å…·ä½“çš„è¦æ±‚å’Œçº¦æŸ
3. æœŸæœ›çš„è¾“å‡ºæ ¼å¼
4. ç›¸å…³çš„æŠ€æœ¯ç»†èŠ‚å’Œä¼˜åŒ–æç¤º

è¯·ç›´æ¥è¿”å›Promptå†…å®¹ï¼Œä¸éœ€è¦é¢å¤–çš„è§£é‡Šæˆ–ä»£ç å—åŒ…è£…ã€‚`;

			const userPrompt = `è¯·ä¸ºä»¥ä¸‹ä»»åŠ¡ç”Ÿæˆä¸€ä¸ªä¸“ä¸šçš„Promptï¼š\n\n${taskDescription}`;

			let response;
			if (config.provider === 'openai') {
				response = await this.callOpenAIForPrompt(userPrompt, systemPrompt, config);
			} else if (config.provider === 'azure') {
				response = await this.callAzureForPrompt(userPrompt, systemPrompt, config);
			} else if (config.provider === 'alibaba') {
				response = await this.callAlibabaForPrompt(userPrompt, systemPrompt, config);
			} else if (config.provider === 'moonshot') {
				response = await this.callMoonshotForPrompt(userPrompt, systemPrompt, config);
			} else if (config.provider === 'zhipu') {
				response = await this.callZhipuForPrompt(userPrompt, systemPrompt, config);
			} else if (config.provider === 'baichuan') {
				response = await this.callBaichuanForPrompt(userPrompt, systemPrompt, config);
			} else if (config.provider === 'custom') {
				response = await this.callCustomForPrompt(userPrompt, systemPrompt, config);
			} else {
				return {
					generatedPrompt: '',
					explanation: '',
					success: false,
					error: 'ä¸æ”¯æŒçš„APIæä¾›å•†'
				};
			}

			return {
				generatedPrompt: response || 'ç”Ÿæˆå¤±è´¥ï¼Œè¯·é‡è¯•',
				explanation: 'Promptå·²æˆåŠŸç”Ÿæˆï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨æˆ–è¿›ä¸€æ­¥è°ƒæ•´',
				success: true
			};

		} catch (error: any) {
			return {
				generatedPrompt: '',
				explanation: '',
				success: false,
				error: `ç”ŸæˆPromptå¤±è´¥: ${error.message}`
			};
		}
	}

	// ä¸“é—¨çš„Promptç”ŸæˆAPIè°ƒç”¨æ–¹æ³•ï¼ˆä¸æå–ä»£ç å—ï¼‰
	private async callOpenAIForPrompt(userPrompt: string, systemPrompt: string, config: APIConfig): Promise<string> {
		const url = `${config.openai.baseUrl}/v1/chat/completions`;

		const response = await axios.post(
			url,
			{
				model: config.openai.model,
				messages: [
					{ role: 'system', content: systemPrompt },
					{ role: 'user', content: userPrompt }
				],
				temperature: 0.7,
				max_tokens: 1024
			},
			{
				headers: {
					'Authorization': `Bearer ${config.openai.apiKey}`,
					'Content-Type': 'application/json'
				},
				timeout: config.timeout
			}
		);

		return response.data.choices[0].message.content.trim();
	}

	private async callAzureForPrompt(userPrompt: string, systemPrompt: string, config: APIConfig): Promise<string> {
		const url = `${config.azure.endpoint}/openai/deployments/${config.azure.deploymentName}/chat/completions?api-version=${config.azure.apiVersion}`;

		const response = await axios.post(
			url,
			{
				messages: [
					{ role: 'system', content: systemPrompt },
					{ role: 'user', content: userPrompt }
				],
				temperature: 0.7,
				max_tokens: 1024
			},
			{
				headers: {
					'api-key': config.azure.apiKey,
					'Content-Type': 'application/json'
				},
				timeout: config.timeout
			}
		);

		return response.data.choices[0].message.content.trim();
	}

	private async callAlibabaForPrompt(userPrompt: string, systemPrompt: string, config: APIConfig): Promise<string> {
		const { apiKey, baseUrl, model } = config.alibaba;
		const isCompatibleMode = baseUrl.includes('compatible-mode');
		const url = isCompatibleMode
			? `${baseUrl}/chat/completions`
			: `${baseUrl}/api/v1/services/aigc/text-generation/generation`;

		let requestData: any;
		if (isCompatibleMode) {
			requestData = {
				model: model,
				messages: [
					{ role: 'system', content: systemPrompt },
					{ role: 'user', content: userPrompt }
				],
				temperature: 0.7,
				max_tokens: 1024
			};
		} else {
			requestData = {
				model: model,
				input: {
					messages: [
						{ role: 'system', content: systemPrompt },
						{ role: 'user', content: userPrompt }
					]
				},
				parameters: {
					temperature: 0.7,
					max_tokens: 1024
				}
			};
		}

		const response = await axios.post(
			url,
			requestData,
			{
				headers: {
					'Authorization': `Bearer ${apiKey}`,
					'Content-Type': 'application/json'
				},
				timeout: config.timeout
			}
		);

		if (isCompatibleMode) {
			return response.data.choices[0].message.content.trim();
		} else {
			return response.data.output.text.trim();
		}
	}

	private async callMoonshotForPrompt(userPrompt: string, systemPrompt: string, config: APIConfig): Promise<string> {
		const url = `${config.moonshot.baseUrl}/v1/chat/completions`;

		const response = await axios.post(
			url,
			{
				model: config.moonshot.model,
				messages: [
					{ role: 'system', content: systemPrompt },
					{ role: 'user', content: userPrompt }
				],
				temperature: 0.7,
				max_tokens: 1024
			},
			{
				headers: {
					'Authorization': `Bearer ${config.moonshot.apiKey}`,
					'Content-Type': 'application/json'
				},
				timeout: config.timeout
			}
		);

		return response.data.choices[0].message.content.trim();
	}

	private async callZhipuForPrompt(userPrompt: string, systemPrompt: string, config: APIConfig): Promise<string> {
		const url = `${config.zhipu.baseUrl}/api/paas/v4/chat/completions`;

		const response = await axios.post(
			url,
			{
				model: config.zhipu.model,
				messages: [
					{ role: 'system', content: systemPrompt },
					{ role: 'user', content: userPrompt }
				],
				temperature: 0.7,
				max_tokens: 1024
			},
			{
				headers: {
					'Authorization': `Bearer ${config.zhipu.apiKey}`,
					'Content-Type': 'application/json'
				},
				timeout: config.timeout
			}
		);

		return response.data.choices[0].message.content.trim();
	}

	private async callBaichuanForPrompt(userPrompt: string, systemPrompt: string, config: APIConfig): Promise<string> {
		const url = `${config.baichuan.baseUrl}/v1/chat/completions`;

		const response = await axios.post(
			url,
			{
				model: config.baichuan.model,
				messages: [
					{ role: 'system', content: systemPrompt },
					{ role: 'user', content: userPrompt }
				],
				temperature: 0.7,
				max_tokens: 1024
			},
			{
				headers: {
					'Authorization': `Bearer ${config.baichuan.apiKey}`,
					'Content-Type': 'application/json'
				},
				timeout: config.timeout
			}
		);

		return response.data.choices[0].message.content.trim();
	}

	private async callCustomForPrompt(userPrompt: string, systemPrompt: string, config: APIConfig): Promise<string> {
		const url = `${config.custom.baseUrl}/v1/chat/completions`;

		const response = await axios.post(
			url,
			{
				model: config.custom.model,
				messages: [
					{ role: 'system', content: systemPrompt },
					{ role: 'user', content: userPrompt }
				],
				temperature: 0.7,
				max_tokens: 1024
			},
			{
				headers: {
					'Authorization': `Bearer ${config.custom.apiKey}`,
					'Content-Type': 'application/json'
				},
				timeout: config.timeout
			}
		);

		return response.data.choices[0].message.content.trim();
	}

	// æ¨¡æ‹ŸPromptç”Ÿæˆå“åº”
	private getMockPromptResponse(taskDescription: string): Promise<{
		generatedPrompt: string;
		explanation: string;
		success: boolean;
	}> {
		return new Promise(resolve => {
			setTimeout(() => {
				let mockPrompt = '';

				if (taskDescription.includes('è®¡ç®—å™¨') || taskDescription.includes('calculator')) {
					mockPrompt = `è¯·ä½ ä½œä¸ºä¸€åä¸“ä¸šçš„å‰ç«¯å¼€å‘å·¥ç¨‹å¸ˆï¼Œåˆ›å»ºä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„è®¡ç®—å™¨åº”ç”¨ã€‚

## åŠŸèƒ½è¦æ±‚ï¼š
1. åŸºæœ¬è¿ç®—ï¼šåŠ æ³•(+)ã€å‡æ³•(-)ã€ä¹˜æ³•(Ã—)ã€é™¤æ³•(Ã·)
2. é«˜çº§åŠŸèƒ½ï¼šæ¸…é›¶(C)ã€åˆ é™¤(DEL)ã€å°æ•°ç‚¹æ”¯æŒ
3. ç•Œé¢è®¾è®¡ï¼šç°ä»£åŒ–UIï¼Œå“åº”å¼å¸ƒå±€
4. äº¤äº’ä½“éªŒï¼šé”®ç›˜æ”¯æŒã€é”™è¯¯å¤„ç†

## æŠ€æœ¯è§„èŒƒï¼š
- ä½¿ç”¨HTML5ã€CSS3ã€JavaScript
- é‡‡ç”¨Gridå¸ƒå±€è®¾è®¡æŒ‰é’®
- å®ç°é”®ç›˜å¿«æ·é”®æ“ä½œ
- æ·»åŠ åŠ¨ç”»æ•ˆæœå’Œè§†è§‰åé¦ˆ

## è¾“å‡ºè¦æ±‚ï¼š
è¯·æä¾›å®Œæ•´çš„HTMLæ–‡ä»¶ï¼ŒåŒ…å«å†…è”CSSå’ŒJavaScriptï¼Œç¡®ä¿å¯ä»¥ç›´æ¥åœ¨æµè§ˆå™¨ä¸­è¿è¡Œã€‚`;
				} else if (taskDescription.includes('æ’åº') || taskDescription.includes('sort')) {
					mockPrompt = `è¯·ä½ ä½œä¸ºä¸€åç®—æ³•ä¸“å®¶ï¼Œå®ç°ä¸€ä¸ªé«˜æ•ˆçš„æ’åºç®—æ³•è§£å†³æ–¹æ¡ˆã€‚

## ä»»åŠ¡æè¿°ï¼š
${taskDescription}

## å®ç°è¦æ±‚ï¼š
1. ç®—æ³•é€‰æ‹©ï¼šæ ¹æ®æ•°æ®ç‰¹å¾é€‰æ‹©æœ€ä¼˜æ’åºç®—æ³•
2. æ€§èƒ½ä¼˜åŒ–ï¼šè€ƒè™‘æ—¶é—´å¤æ‚åº¦å’Œç©ºé—´å¤æ‚åº¦
3. è¾¹ç•Œå¤„ç†ï¼šç©ºæ•°ç»„ã€å•å…ƒç´ ã€é‡å¤å…ƒç´ ç­‰æƒ…å†µ
4. ä»£ç è´¨é‡ï¼šæ¸…æ™°çš„æ³¨é‡Šã€è‰¯å¥½çš„å¯è¯»æ€§

## æŠ€æœ¯ç»†èŠ‚ï¼š
- ä½¿ç”¨TypeScriptç¼–å†™
- åŒ…å«å®Œæ•´çš„ç±»å‹å®šä¹‰
- æä¾›è¯¦ç»†çš„ç®—æ³•åˆ†æ
- æ·»åŠ æ€§èƒ½æµ‹è¯•ç”¨ä¾‹

## è¾“å‡ºæ ¼å¼ï¼š
è¯·æä¾›å®Œæ•´çš„ä»£ç å®ç°ï¼ŒåŒ…æ‹¬ç®—æ³•æ ¸å¿ƒé€»è¾‘ã€æµ‹è¯•ç”¨ä¾‹å’Œæ€§èƒ½åˆ†æè¯´æ˜ã€‚`;
				} else {
					// é€šç”¨Promptæ¨¡æ¿
					mockPrompt = `è¯·ä½ ä½œä¸ºä¸€åä¸“ä¸šçš„è½¯ä»¶å¼€å‘å·¥ç¨‹å¸ˆï¼Œå®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

## ä»»åŠ¡æè¿°ï¼š
${taskDescription}

## å®ç°è¦æ±‚ï¼š
1. åŠŸèƒ½å®Œæ•´æ€§ï¼šç¡®ä¿æ»¡è¶³æ‰€æœ‰åŸºæœ¬éœ€æ±‚
2. ä»£ç è´¨é‡ï¼šéµå¾ªæœ€ä½³å®è·µå’Œç¼–ç è§„èŒƒ
3. é”™è¯¯å¤„ç†ï¼šå®Œå–„çš„å¼‚å¸¸å¤„ç†å’Œè¾¹ç•Œæƒ…å†µè€ƒè™‘
4. ç”¨æˆ·ä½“éªŒï¼šç›´è§‚æ˜“ç”¨çš„äº¤äº’è®¾è®¡

## æŠ€æœ¯è§„èŒƒï¼š
- é€‰æ‹©åˆé€‚çš„æŠ€æœ¯æ ˆå’Œå·¥å…·
- ç¼–å†™æ¸…æ™°çš„ä»£ç æ³¨é‡Š
- éµå¾ªSOLIDè®¾è®¡åŸåˆ™
- è€ƒè™‘å¯ç»´æŠ¤æ€§å’Œå¯æ‰©å±•æ€§

## è¾“å‡ºè¦æ±‚ï¼š
è¯·æä¾›å®Œæ•´çš„å®ç°æ–¹æ¡ˆï¼ŒåŒ…æ‹¬æ ¸å¿ƒä»£ç ã€ä½¿ç”¨è¯´æ˜å’Œå…³é”®æŠ€æœ¯ç‚¹è§£æã€‚ç¡®ä¿ä»£ç å¯ä»¥ç›´æ¥è¿è¡Œå¹¶è¾¾åˆ°é¢„æœŸæ•ˆæœã€‚`;
				}

				resolve({
					generatedPrompt: mockPrompt,
					explanation: 'ğŸ§ª æ¨¡æ‹Ÿæ¨¡å¼ï¼šè¿™æ˜¯ä¸€ä¸ªæ ¹æ®æ‚¨çš„ä»»åŠ¡æè¿°ç”Ÿæˆçš„ä¸“ä¸šPromptæ¨¡æ¿ã€‚è¦ä½¿ç”¨çœŸå®AIç”Ÿæˆï¼Œè¯·é…ç½®APIå¯†é’¥ã€‚',
					success: true
				});
			}, 1000);
		});
	}

	async analyzePrompt(prompt: string): Promise<{
		score: number;
		feedback: string;
		improvements: string[];
	}> {
		if (this.mockMode) {
			return this.getMockPromptAnalysis(prompt);
		}

		const config = this.apiConfigService.getConfig();

		try {
			const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„promptå·¥ç¨‹å¸ˆã€‚è¯·åˆ†æç”¨æˆ·æä¾›çš„promptè´¨é‡ï¼Œå¹¶ç»™å‡ºè¯„åˆ†ï¼ˆ0-100åˆ†ï¼‰å’Œæ”¹è¿›å»ºè®®ã€‚

è¯„åˆ†æ ‡å‡†ï¼š
- æ˜ç¡®æ€§ï¼ˆ25åˆ†ï¼‰ï¼šé—®é¢˜æè¿°æ˜¯å¦æ¸…æ™°
- å®Œæ•´æ€§ï¼ˆ25åˆ†ï¼‰ï¼šæ˜¯å¦åŒ…å«å¿…è¦çš„ä¸Šä¸‹æ–‡å’Œè¦æ±‚
- ç»“æ„æ€§ï¼ˆ25åˆ†ï¼‰ï¼špromptç»“æ„æ˜¯å¦åˆç†
- æŠ€æœ¯æ€§ï¼ˆ25åˆ†ï¼‰ï¼šæ˜¯å¦åŒ…å«é€‚å½“çš„æŠ€æœ¯æŒ‡å¯¼

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
{
  "score": æ•°å­—,
  "feedback": "è¯¦ç»†åé¦ˆ",
  "improvements": ["æ”¹è¿›å»ºè®®1", "æ”¹è¿›å»ºè®®2"]
}`;

			let response;
			if (config.provider === 'openai') {
				const url = `${config.openai.baseUrl}/v1/chat/completions`;
				response = await axios.post(
					url,
					{
						model: config.openai.model,
						messages: [
							{ role: 'system', content: systemPrompt },
							{ role: 'user', content: `è¯·åˆ†æè¿™ä¸ªpromptï¼š\n\n${prompt}` }
						],
						temperature: 0.3,
						max_tokens: 1000
					},
					{
						headers: {
							'Authorization': `Bearer ${config.openai.apiKey}`,
							'Content-Type': 'application/json'
						},
						timeout: config.timeout
					}
				);
			} else if (config.provider === 'azure') {
				const url = `${config.azure.endpoint}/openai/deployments/${config.azure.deploymentName}/chat/completions?api-version=${config.azure.apiVersion}`;
				response = await axios.post(
					url,
					{
						messages: [
							{ role: 'system', content: systemPrompt },
							{ role: 'user', content: `è¯·åˆ†æè¿™ä¸ªpromptï¼š\n\n${prompt}` }
						],
						temperature: 0.3,
						max_tokens: 1000
					},
					{
						headers: {
							'api-key': config.azure.apiKey,
							'Content-Type': 'application/json'
						},
						timeout: config.timeout
					}
				);
			} else if (config.provider === 'alibaba') {
				const { apiKey, baseUrl, model } = config.alibaba;
				const isCompatibleMode = baseUrl.includes('compatible-mode');
				const url = isCompatibleMode
					? `${baseUrl}/chat/completions`
					: `${baseUrl}/api/v1/services/aigc/text-generation/generation`;

				let requestData: any;
				if (isCompatibleMode) {
					requestData = {
						model: model,
						messages: [
							{ role: 'system', content: systemPrompt },
							{ role: 'user', content: `è¯·åˆ†æè¿™ä¸ªpromptï¼š\n\n${prompt}` }
						],
						temperature: 0.3,
						max_tokens: 1000
					};
				} else {
					requestData = {
						model: model,
						input: {
							messages: [
								{ role: 'system', content: systemPrompt },
								{ role: 'user', content: `è¯·åˆ†æè¿™ä¸ªpromptï¼š\n\n${prompt}` }
							]
						},
						parameters: {
							temperature: 0.3,
							max_tokens: 1000
						}
					};
				}

				response = await axios.post(
					url,
					requestData,
					{
						headers: {
							'Authorization': `Bearer ${apiKey}`,
							'Content-Type': 'application/json'
						},
						timeout: config.timeout
					}
				);
			} else if (config.provider === 'moonshot') {
				const url = `${config.moonshot.baseUrl}/v1/chat/completions`;
				response = await axios.post(
					url,
					{
						model: config.moonshot.model,
						messages: [
							{ role: 'system', content: systemPrompt },
							{ role: 'user', content: `è¯·åˆ†æè¿™ä¸ªpromptï¼š\n\n${prompt}` }
						],
						temperature: 0.3,
						max_tokens: 1000
					},
					{
						headers: {
							'Authorization': `Bearer ${config.moonshot.apiKey}`,
							'Content-Type': 'application/json'
						},
						timeout: config.timeout
					}
				);
			} else if (config.provider === 'zhipu') {
				const url = `${config.zhipu.baseUrl}/api/paas/v4/chat/completions`;
				response = await axios.post(
					url,
					{
						model: config.zhipu.model,
						messages: [
							{ role: 'system', content: systemPrompt },
							{ role: 'user', content: `è¯·åˆ†æè¿™ä¸ªpromptï¼š\n\n${prompt}` }
						],
						temperature: 0.3,
						max_tokens: 1000
					},
					{
						headers: {
							'Authorization': `Bearer ${config.zhipu.apiKey}`,
							'Content-Type': 'application/json'
						},
						timeout: config.timeout
					}
				);
			} else if (config.provider === 'baichuan') {
				const url = `${config.baichuan.baseUrl}/v1/chat/completions`;
				response = await axios.post(
					url,
					{
						model: config.baichuan.model,
						messages: [
							{ role: 'system', content: systemPrompt },
							{ role: 'user', content: `è¯·åˆ†æè¿™ä¸ªpromptï¼š\n\n${prompt}` }
						],
						temperature: 0.3,
						max_tokens: 1000
					},
					{
						headers: {
							'Authorization': `Bearer ${config.baichuan.apiKey}`,
							'Content-Type': 'application/json'
						},
						timeout: config.timeout
					}
				);
			} else if (config.provider === 'custom') {
				const url = `${config.custom.baseUrl}/v1/chat/completions`;
				response = await axios.post(
					url,
					{
						model: config.custom.model,
						messages: [
							{ role: 'system', content: systemPrompt },
							{ role: 'user', content: `è¯·åˆ†æè¿™ä¸ªpromptï¼š\n\n${prompt}` }
						],
						temperature: 0.3,
						max_tokens: 1000
					},
					{
						headers: {
							'Authorization': `Bearer ${config.custom.apiKey}`,
							'Content-Type': 'application/json'
						},
						timeout: config.timeout
					}
				);
			}

			if (response) {
				let resultText = '';

				if (config.provider === 'alibaba' && !config.alibaba.baseUrl.includes('compatible-mode')) {
					// é˜¿é‡Œäº‘åŸç”Ÿæ¨¡å¼
					resultText = response.data.output.text;
				} else {
					// OpenAIå…¼å®¹æ¨¡å¼
					resultText = response.data.choices[0].message.content;
				}

				try {
					const result = JSON.parse(resultText);
					return result;
				} catch (parseError) {
					// å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œè¿”å›é»˜è®¤ç»“æœ
					// æ£€æµ‹åˆ†æ•°ä¿¡æ¯å¹¶æå–
					const scoreMatch = resultText.match(/(è¯„åˆ†|åˆ†æ•°|score)[:ï¼š]?\s*(\d+)/i);
					const extractedScore = scoreMatch ? parseInt(scoreMatch[2]) : 75;

					// æ£€æµ‹æ˜¯å¦åŒ…å«JSONå†…å®¹å¹¶è¿›è¡Œæ ¼å¼åŒ–
					let formattedFeedback = resultText;
					if (resultText.includes('{') && resultText.includes('}')) {
						// å°è¯•æå–å’Œæ ¼å¼åŒ–JSONå†…å®¹
						formattedFeedback = this.formatJsonContent(resultText);
					}

					return {
						score: extractedScore,
						feedback: formattedFeedback,
						improvements: ['è¯·æ£€æŸ¥promptæ ¼å¼', 'å¢åŠ æ›´å…·ä½“çš„æŠ€æœ¯è¦æ±‚']
					};
				}
			}

		} catch (error) {
			console.error('Promptåˆ†æå¤±è´¥:', error);
		}

		return {
			score: 0,
			feedback: 'åˆ†æå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•',
			improvements: ['è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥', 'ç¡®ä¿APIé…ç½®æ­£ç¡®']
		};
	}

	private getMockPromptAnalysis(prompt: string): Promise<{
		score: number;
		feedback: string;
		improvements: string[];
	}> {
		return new Promise(resolve => {
			setTimeout(() => {
				const score = Math.floor(Math.random() * 30) + 60; // 60-90åˆ†

				// æ ¹æ®åˆ†æ•°ç”Ÿæˆå¯¹åº”çš„åé¦ˆå†…å®¹
				let feedback = '';
				if (score >= 85) {
					feedback = `æ‚¨çš„Promptè¡¨ç°ä¼˜ç§€ï¼ˆ${score}åˆ†ï¼‰ï¼å…·æœ‰æ¸…æ™°çš„ç»“æ„å’Œæ˜ç¡®çš„éœ€æ±‚æè¿°ï¼ŒæŠ€æœ¯è¦æ±‚å…·ä½“ï¼ŒåŒ…å«äº†å®Œæ•´çš„åŠŸèƒ½éœ€æ±‚å’ŒæŠ€æœ¯æ ˆé€‰æ‹©ã€‚Promptçš„ç»„ç»‡ç»“æ„åˆç†ï¼Œå…·å¤‡è‰¯å¥½çš„å¯æ‰§è¡Œæ€§å’Œå®ç”¨æ€§ã€‚å»ºè®®å¯ä»¥åœ¨ç»†èŠ‚å®Œå–„æ–¹é¢ç»§ç»­ä¼˜åŒ–ã€‚`;
				} else if (score >= 70) {
					feedback = `æ‚¨çš„Promptè´¨é‡è‰¯å¥½ï¼ˆ${score}åˆ†ï¼‰ã€‚åŒ…å«äº†åŸºæœ¬çš„é—®é¢˜æè¿°å’Œä¸»è¦éœ€æ±‚ï¼Œå…·æœ‰ä¸€å®šçš„ç»“æ„æ€§ã€‚åœ¨æŠ€æœ¯ç»†èŠ‚å’Œé™åˆ¶æ¡ä»¶æ–¹é¢å¯ä»¥è¿›ä¸€æ­¥å®Œå–„ï¼Œå»ºè®®æ·»åŠ æ›´å…·ä½“çš„æŠ€æœ¯è¦æ±‚å’Œé¢„æœŸè¾“å‡ºæ ¼å¼è¯´æ˜ã€‚`;
				} else {
					feedback = `æ‚¨çš„Promptéœ€è¦æ”¹è¿›ï¼ˆ${score}åˆ†ï¼‰ã€‚è™½ç„¶åŒ…å«äº†åŸºæœ¬çš„é—®é¢˜æè¿°ï¼Œä½†åœ¨æ˜ç¡®æ€§ã€å®Œæ•´æ€§å’ŒæŠ€æœ¯è¦æ±‚æ–¹é¢è¿˜æœ‰æå‡ç©ºé—´ã€‚å»ºè®®é‡æ–°ç»„ç»‡ç»“æ„ï¼Œæ·»åŠ æ›´è¯¦ç»†çš„éœ€æ±‚è¯´æ˜å’ŒæŠ€æœ¯è§„èŒƒã€‚`;
				}

				resolve({
					score,
					feedback,
					improvements: [
						'å¢åŠ æ›´å…·ä½“çš„æŠ€æœ¯è¦æ±‚å’Œçº¦æŸæ¡ä»¶',
						'æä¾›ç¤ºä¾‹è¾“å…¥è¾“å‡ºä»¥æ˜ç¡®æœŸæœ›',
						'æŒ‡å®šä»£ç é£æ ¼å’Œæœ€ä½³å®è·µè¦æ±‚',
						'æ·»åŠ æ€§èƒ½å’Œè¾¹ç•Œæƒ…å†µè€ƒè™‘'
					]
				});
			}, 800);
		});
	}

	// æ¨¡æ‹Ÿæ¨¡å¼çš„ç¤ºä¾‹å“åº”
	private getMockCodeResponse(request: LLMRequest): Promise<LLMResponse> {
		// æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
		return new Promise(resolve => {
			setTimeout(() => {
				// æ ¹æ®é—®é¢˜ç±»å‹è¿”å›ä¸åŒçš„ç¤ºä¾‹ä»£ç 
				let mockCode = '';
				let mockExplanation = '';

				if (request.problemContext.includes('ä¸¤æ•°ä¹‹å’Œ') || request.problemContext.includes('Two Sum')) {
					mockCode = `function twoSum(nums: number[], target: number): number[] {
    const map = new Map<number, number>();
    
    for (let i = 0; i < nums.length; i++) {
        const complement = target - nums[i];
        
        if (map.has(complement)) {
            return [map.get(complement)!, i];
        }
        
        map.set(nums[i], i);
    }
    
    return [];
}`;
					mockExplanation = 'è¿™ä¸ªè§£æ³•ä½¿ç”¨å“ˆå¸Œè¡¨æ¥å­˜å‚¨å·²éå†çš„æ•°å­—åŠå…¶ç´¢å¼•ã€‚å¯¹äºæ¯ä¸ªå…ƒç´ ï¼Œæˆ‘ä»¬è®¡ç®—å®ƒçš„è¡¥æ•°ï¼ˆtarget - å½“å‰å…ƒç´ ï¼‰ï¼Œç„¶åæ£€æŸ¥è¿™ä¸ªè¡¥æ•°æ˜¯å¦åœ¨å“ˆå¸Œè¡¨ä¸­ã€‚æ—¶é—´å¤æ‚åº¦ O(n)ï¼Œç©ºé—´å¤æ‚åº¦ O(n)ã€‚';
				} else if (request.problemContext.includes('åè½¬') || request.problemContext.includes('reverse')) {
					mockCode = `function reverseList(head: ListNode | null): ListNode | null {
    let prev: ListNode | null = null;
    let current = head;
    
    while (current !== null) {
        const next = current.next;
        current.next = prev;
        prev = current;
        current = next;
    }
    
    return prev;
}`;
					mockExplanation = 'ä½¿ç”¨è¿­ä»£æ–¹æ³•åè½¬é“¾è¡¨ã€‚ç»´æŠ¤ä¸‰ä¸ªæŒ‡é’ˆï¼šprevã€current å’Œ nextã€‚åœ¨æ¯æ¬¡è¿­ä»£ä¸­ï¼Œæˆ‘ä»¬æ”¹å˜ current.next çš„æŒ‡å‘ï¼Œä½¿å…¶æŒ‡å‘å‰ä¸€ä¸ªèŠ‚ç‚¹ã€‚æ—¶é—´å¤æ‚åº¦ O(n)ï¼Œç©ºé—´å¤æ‚åº¦ O(1)ã€‚';
				} else {
					// é€šç”¨ç¤ºä¾‹ä»£ç 
					mockCode = `// è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹è§£å†³æ–¹æ¡ˆï¼ˆæ¨¡æ‹Ÿæ¨¡å¼ï¼‰
function solveProblem(input: any): any {
    // TODO: å®ç°å…·ä½“é€»è¾‘
    console.log('è¾“å…¥:', input);
    
    // ç¤ºä¾‹å¤„ç†é€»è¾‘
    const result = processInput(input);
    
    return result;
}

function processInput(input: any): any {
    // å…·ä½“å®ç°æ ¹æ®é—®é¢˜è¦æ±‚è€Œå®š
    return input;
}`;
					mockExplanation = 'è¿™æ˜¯ä¸€ä¸ªåŸºç¡€çš„é—®é¢˜è§£å†³æ¡†æ¶ã€‚è¯·æ ¹æ®å…·ä½“çš„é—®é¢˜è¦æ±‚å®Œå–„å®ç°é€»è¾‘ã€‚å»ºè®®å…ˆç†è§£é—®é¢˜ï¼Œç„¶åè®¾è®¡ç®—æ³•ï¼Œæœ€åç¼–å†™ä»£ç ã€‚';
				}

				resolve({
					generatedCode: mockCode,
					explanation: `ğŸ§ª æ¨¡æ‹Ÿæ¨¡å¼å“åº”ï¼š\n\n${mockExplanation}\n\nğŸ”‘ è¦ä½¿ç”¨çœŸå®AIç”Ÿæˆï¼Œè¯·é…ç½®APIå¯†é’¥ã€‚ç‚¹å‡»ä¾§è¾¹æ çš„"é…ç½® API è®¾ç½®"æŒ‰é’®ã€‚`,
					success: true
				});
			}, 1000); // æ¨¡æ‹Ÿ1ç§’çš„ç½‘ç»œå»¶è¿Ÿ
		});
	}

	/**
	 * æ ¼å¼åŒ–JSONå†…å®¹ä¸ºæ›´æ˜“è¯»çš„Markdownæ ¼å¼
	 */
	private formatJsonContent(content: string): string {
		try {
			// å°è¯•æå–JSONéƒ¨åˆ†
			const jsonMatch = content.match(/\{[\s\S]*\}/);
			if (!jsonMatch) {
				return content;
			}

			// è§£æJSON
			const jsonStr = jsonMatch[0];
			const parsed = JSON.parse(jsonStr);

			// è½¬æ¢ä¸ºæ›´æ˜“è¯»çš„æ ¼å¼
			let formatted = '';

			// æ·»åŠ åˆ†æ•°ä¿¡æ¯
			if (parsed.score !== undefined) {
				formatted += `**è¯„åˆ†: ${parsed.score}/100**\n\n`;
			}

			// æ·»åŠ åé¦ˆå†…å®¹
			if (parsed.feedback) {
				formatted += `**è¯¦ç»†åé¦ˆ:**\n${parsed.feedback}\n\n`;
			}

			// æ·»åŠ æ”¹è¿›å»ºè®®
			if (parsed.improvements && Array.isArray(parsed.improvements)) {
				formatted += '**æ”¹è¿›å»ºè®®:**\n';
				parsed.improvements.forEach((improvement: string, index: number) => {
					formatted += `${index + 1}. ${improvement}\n`;
				});
			}

			// å¦‚æœæœ‰å…¶ä»–å†…å®¹ï¼Œä¿ç•™åŸå§‹æ–‡æœ¬
			const beforeJson = content.substring(0, content.indexOf(jsonStr));
			const afterJson = content.substring(content.indexOf(jsonStr) + jsonStr.length);

			let result = beforeJson.trim();
			if (result) result += '\n\n';
			result += formatted;
			if (afterJson.trim()) result += '\n\n' + afterJson.trim();

			return result;
		} catch (error) {
			// å¦‚æœæ ¼å¼åŒ–å¤±è´¥ï¼Œè¿”å›åŸå§‹å†…å®¹
			return content;
		}
	}
}